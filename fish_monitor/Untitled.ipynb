{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:32:18.559088Z",
     "start_time": "2020-03-11T21:32:12.395061Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:38:20.399163Z",
     "start_time": "2020-03-11T21:38:20.395895Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = './dataset/the-nature-conservancy-fisheries-monitoring/train/'\n",
    "TEST_DIR = './dataset/the-nature-conservancy-fisheries-monitoring/test_stg1/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "ROWS = 90  \n",
    "COLS = 160 \n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:34:11.947463Z",
     "start_time": "2020-03-11T21:34:11.943994Z"
    }
   },
   "source": [
    "### Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is from https://www.kaggle.com/jeffd23/deep-learning-in-the-deep-blue-lb-1-279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:36:32.306135Z",
     "start_time": "2020-03-11T21:36:32.301008Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:38:21.985648Z",
     "start_time": "2020-03-11T21:38:21.944966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719 photos of ALB\n",
      "200 photos of BET\n",
      "117 photos of DOL\n",
      "67 photos of LAG\n",
      "465 photos of NoF\n",
      "299 photos of OTHER\n",
      "176 photos of SHARK\n",
      "734 photos of YFT\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for fish in FISH_CLASSES:\n",
    "    fish_files = get_images(fish)\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    y_all.extend(y_fish)\n",
    "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:38:47.861422Z",
     "start_time": "2020-03-11T21:38:47.857406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3777,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:52:25.478902Z",
     "start_time": "2020-03-11T21:51:36.472264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 3777\n",
      "Processed 1000 of 3777\n",
      "Processed 2000 of 3777\n",
      "Processed 3000 of 3777\n",
      "(3777, 90, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:52:25.582477Z",
     "start_time": "2020-03-11T21:52:25.576454Z"
    }
   },
   "outputs": [],
   "source": [
    "X_all = X_all.transpose([0,3,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:52:25.620067Z",
     "start_time": "2020-03-11T21:52:25.614200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3777, 3, 90, 160)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:59:22.578059Z",
     "start_time": "2020-03-11T21:59:22.574161Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:59:41.867476Z",
     "start_time": "2020-03-11T21:59:41.217186Z"
    }
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "y_all = to_categorical(y_all,8)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T22:42:27.903300Z",
     "start_time": "2020-03-11T22:42:27.898228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1375,  160,   93,   54,  372,  239,  141,  587], dtype=uint64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try add maxpool layer\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# pass\n",
    "\n",
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, channel_3, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        #         pass\n",
    "        self.cn1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.cn1.weight)\n",
    "        \n",
    "        self.cn2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.cn2.weight)\n",
    "        \n",
    "        self.cn3 = nn.Conv2d(channel_2, channel_3, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.cn3.weight)\n",
    "        \n",
    "        self.fc = nn.Linear(channel_3 * 4 * 4, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        \n",
    "        self.batchnorm_conv1 = nn.BatchNorm2d(channel_1)\n",
    "        self.batchnorm_conv2 = nn.BatchNorm2d(channel_2)\n",
    "        self.batchnorm_conv3 = nn.BatchNorm2d(channel_2)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(p=0.2)\n",
    "        self.dropout2 = nn.Dropout2d(p=0.2)\n",
    "        self.dropout3 = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "\n",
    "        h1 = F.relu(self.cn1(x))\n",
    "        h1_pool = self.pool1(h1)\n",
    "\n",
    "        \n",
    "        h2 = F.relu(self.cn2(h1_pool))\n",
    "        h2_pool = self.pool2(h2)\n",
    "        \n",
    "        h3 = F.relu(self.cn3(h2_pool))\n",
    "        h3_pool = self.pool3(h3)\n",
    "\n",
    "        \n",
    "        \n",
    "        scores = self.fc(flatten(h3_pool))\n",
    "        \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        return scores\n",
    "    \n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             \n",
    "################################################################################\n",
    "\n",
    "\n",
    "model = ThreeLayerConvNet(in_channel=3, channel_1=64, channel_2=64, channel_3=64, num_classes=10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "# You should get at least 70% accuracy\n",
    "train_part34(model, optimizer, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
