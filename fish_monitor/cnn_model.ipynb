{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:05:24.262199Z",
     "start_time": "2020-03-12T21:05:06.059177Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:05:24.331018Z",
     "start_time": "2020-03-12T21:05:24.327903Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = './dataset/the-nature-conservancy-fisheries-monitoring/train/'\n",
    "TEST_DIR = './dataset/the-nature-conservancy-fisheries-monitoring/test_stg1/'\n",
    "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
    "ROWS = 128  \n",
    "COLS = 128\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T21:34:11.947463Z",
     "start_time": "2020-03-11T21:34:11.943994Z"
    }
   },
   "source": [
    "### Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:05:24.414609Z",
     "start_time": "2020-03-12T21:05:24.411317Z"
    }
   },
   "outputs": [],
   "source": [
    "# This part is from https://www.kaggle.com/jeffd23/deep-learning-in-the-deep-blue-lb-1-279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:05:24.523258Z",
     "start_time": "2020-03-12T21:05:24.516228Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
    "    return images\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:05:24.654829Z",
     "start_time": "2020-03-12T21:05:24.614915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719 photos of ALB\n",
      "200 photos of BET\n",
      "117 photos of DOL\n",
      "67 photos of LAG\n",
      "465 photos of NoF\n",
      "299 photos of OTHER\n",
      "176 photos of SHARK\n",
      "734 photos of YFT\n"
     ]
    }
   ],
   "source": [
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for fish in FISH_CLASSES:\n",
    "    fish_files = get_images(fish)\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    y_all.extend(y_fish)\n",
    "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:05:24.731566Z",
     "start_time": "2020-03-12T21:05:24.726447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3777,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:51.460742Z",
     "start_time": "2020-03-12T21:05:24.821535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 3777\n",
      "Processed 1000 of 3777\n",
      "Processed 2000 of 3777\n",
      "Processed 3000 of 3777\n",
      "(3777, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:51.585705Z",
     "start_time": "2020-03-12T21:08:51.582669Z"
    }
   },
   "outputs": [],
   "source": [
    "X_all = X_all.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:51.734882Z",
     "start_time": "2020-03-12T21:08:51.728651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3777, 3, 128, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:51.872905Z",
     "start_time": "2020-03-12T21:08:51.869832Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:52.586402Z",
     "start_time": "2020-03-12T21:08:51.994759Z"
    }
   },
   "outputs": [],
   "source": [
    "# One Hot Encoding Labels\n",
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "# y_all = to_categorical(y_all,8)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.01, \n",
    "                                                    random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:52.796400Z",
     "start_time": "2020-03-12T21:08:52.789567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3739,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:53.029968Z",
     "start_time": "2020-03-12T21:08:53.010606Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_valid = torch.from_numpy(X_valid)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_valid = torch.from_numpy(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:53.334234Z",
     "start_time": "2020-03-12T21:08:53.331060Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dataset_train = data.TensorDataset(X_train,y_train) # create your datset\n",
    "loader_train = data.DataLoader(my_dataset_train,batch_size=50) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:53.645119Z",
     "start_time": "2020-03-12T21:08:53.640748Z"
    }
   },
   "outputs": [],
   "source": [
    "my_dataset_val = data.TensorDataset(X_valid,y_valid) # create your datset\n",
    "loader_val = data.DataLoader(my_dataset_val,batch_size=100) # create your dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:54.098878Z",
     "start_time": "2020-03-12T21:08:54.088706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "# print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:54.474004Z",
     "start_time": "2020-03-12T21:08:54.464662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Try add maxpool layer\n",
    "model = None\n",
    "optimizer = None\n",
    "\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "# pass\n",
    "\n",
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, channel_3, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        #         pass\n",
    "        self.cn1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.cn1.weight)\n",
    "        \n",
    "        self.cn2 = nn.Conv2d(channel_1, channel_2, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.cn2.weight)\n",
    "        \n",
    "        self.cn3 = nn.Conv2d(channel_2, channel_3, kernel_size=5, stride=1, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.cn3.weight)\n",
    "        \n",
    "        self.fc = nn.Linear(channel_3*16*16, num_classes)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        \n",
    "        self.batchnorm_conv1 = nn.BatchNorm2d(channel_1)\n",
    "        self.batchnorm_conv2 = nn.BatchNorm2d(channel_2)\n",
    "        self.batchnorm_conv3 = nn.BatchNorm2d(channel_3)\n",
    "        \n",
    "#         self.dropout1 = nn.Dropout2d(p=0.2)\n",
    "#         self.dropout2 = nn.Dropout2d(p=0.2)\n",
    "#         self.dropout3 = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.pool3 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "\n",
    "        h1 = F.relu(self.cn1(x))\n",
    "        \n",
    "        h1_pool = self.pool1(h1)\n",
    "        \n",
    "        h1_pool = self.batchnorm_conv1(h1_pool)\n",
    "        \n",
    "        h2 = F.relu(self.cn2(h1_pool))\n",
    "        \n",
    "        h2_pool = self.pool2(h2)\n",
    "        \n",
    "        h2_pool = self.batchnorm_conv2(h2_pool)\n",
    "        \n",
    "        h3 = F.relu(self.cn3(h2_pool))\n",
    "        \n",
    "        h3_pool = self.pool3(h3)\n",
    "        \n",
    "        h3_pool = self.batchnorm_conv3(h3_pool)\n",
    "\n",
    "        scores = self.fc(flatten(h3_pool))\n",
    "\n",
    "        return self.softmax(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:54.794096Z",
     "start_time": "2020-03-12T21:08:54.787101Z"
    }
   },
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "def train_part(loader_train,\n",
    "               model, \n",
    "               optimizer, \n",
    "               epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "#     n_samples = x_train.shape[0]\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "        if e % print_every == 1:\n",
    "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "            check_accuracy_part(loader_val, model)\n",
    "            check_accuracy_part(loader_train, model)\n",
    "            print(\"\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:55.128763Z",
     "start_time": "2020-03-12T21:08:55.122639Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part(loader,\n",
    "                        model):\n",
    "    \"\"\"\n",
    "    Check the accuracy of a classification model.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_fn: A function that performs the forward pass of the model,\n",
    "      with the signature scores = model_fn(x, params)\n",
    "    - params: List of PyTorch Tensors giving parameters of the model\n",
    "    \n",
    "    Returns: Nothing, but prints the accuracy of the model\n",
    "    \"\"\"\n",
    "    print('Checking accuracy on the validation set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T21:08:55.472269Z",
     "start_time": "2020-03-12T21:08:55.469374Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:10:53.356088Z",
     "start_time": "2020-03-12T21:08:55.769578Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 74, loss = 1.8325\n",
      "Checking accuracy on the validation set\n",
      "Got 21 / 38 correct (55.26)\n",
      "Checking accuracy on the validation set\n",
      "Got 2089 / 3739 correct (55.87)\n",
      "\n",
      "Iteration 74, loss = 1.3891\n",
      "Checking accuracy on the validation set\n",
      "Got 32 / 38 correct (84.21)\n",
      "Checking accuracy on the validation set\n",
      "Got 3084 / 3739 correct (82.48)\n",
      "\n",
      "Iteration 74, loss = 1.2992\n",
      "Checking accuracy on the validation set\n",
      "Got 33 / 38 correct (86.84)\n",
      "Checking accuracy on the validation set\n",
      "Got 3311 / 3739 correct (88.55)\n",
      "\n",
      "Iteration 74, loss = 1.2991\n",
      "Checking accuracy on the validation set\n",
      "Got 36 / 38 correct (94.74)\n",
      "Checking accuracy on the validation set\n",
      "Got 3450 / 3739 correct (92.27)\n",
      "\n",
      "Iteration 74, loss = 1.2990\n",
      "Checking accuracy on the validation set\n",
      "Got 35 / 38 correct (92.11)\n",
      "Checking accuracy on the validation set\n",
      "Got 3516 / 3739 correct (94.04)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate =1e-2\n",
    "model = ThreeLayerConvNet(in_channel=3, channel_1=32, channel_2=16, channel_3=8, num_classes=8)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.95)\n",
    "final_model = train_part(loader_train, model, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:33:31.788623Z",
     "start_time": "2020-03-12T22:33:31.782863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeLayerConvNet(\n",
       "  (cn1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (cn2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (cn3): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       "  (batchnorm_conv1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_conv2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_conv3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:40:21.111112Z",
     "start_time": "2020-03-12T22:40:21.096732Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = './model/cnn.pth'\n",
    "torch.save(final_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:40:51.305316Z",
     "start_time": "2020-03-12T22:40:51.301412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeLayerConvNet(\n",
       "  (cn1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (cn2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (cn3): Conv2d(16, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       "  (batchnorm_conv1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_conv2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_conv3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:41:43.475745Z",
     "start_time": "2020-03-12T22:40:57.138276Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files = [im for im in os.listdir(TEST_DIR)]\n",
    "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(TEST_DIR+im)\n",
    "    \n",
    "# test_preds = model.predict(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:41:43.805025Z",
     "start_time": "2020-03-12T22:41:43.801872Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test.transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:41:44.106075Z",
     "start_time": "2020-03-12T22:41:44.101053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3, 128, 128)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:41:44.370586Z",
     "start_time": "2020-03-12T22:41:44.368105Z"
    }
   },
   "outputs": [],
   "source": [
    "test = torch.from_numpy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:41:59.468229Z",
     "start_time": "2020-03-12T22:41:44.768653Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = model(test.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:41:59.953998Z",
     "start_time": "2020-03-12T22:41:59.943576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1321e-01, 1.2301e-03, 2.3799e-03,  ..., 7.7977e-05, 2.9596e-01,\n",
       "         3.3732e-03],\n",
       "        [9.9990e-01, 9.2013e-11, 5.8428e-09,  ..., 1.0398e-09, 4.8902e-08,\n",
       "         9.9583e-05],\n",
       "        [9.9998e-01, 4.2699e-07, 3.6368e-08,  ..., 5.5728e-07, 1.7873e-05,\n",
       "         8.0633e-08],\n",
       "        ...,\n",
       "        [7.0890e-03, 4.8651e-07, 2.0195e-06,  ..., 6.9889e-06, 1.0576e-04,\n",
       "         2.7931e-06],\n",
       "        [8.5088e-01, 1.6343e-04, 1.6566e-07,  ..., 2.4682e-05, 1.5261e-04,\n",
       "         1.4845e-01],\n",
       "        [9.9985e-01, 3.7505e-05, 5.9571e-07,  ..., 7.8504e-06, 8.7242e-10,\n",
       "         2.0785e-06]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:00.306687Z",
     "start_time": "2020-03-12T22:42:00.303003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FISH_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:00.726069Z",
     "start_time": "2020-03-12T22:42:00.717056Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = test_preds.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:01.884490Z",
     "start_time": "2020-03-12T22:42:01.151596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_02082.jpg</td>\n",
       "      <td>0.513207</td>\n",
       "      <td>1.230079e-03</td>\n",
       "      <td>2.379873e-03</td>\n",
       "      <td>2.242678e-04</td>\n",
       "      <td>1.835492e-01</td>\n",
       "      <td>7.797730e-05</td>\n",
       "      <td>2.959583e-01</td>\n",
       "      <td>3.373205e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_02096.jpg</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>9.201301e-11</td>\n",
       "      <td>5.842765e-09</td>\n",
       "      <td>3.926248e-09</td>\n",
       "      <td>9.943790e-09</td>\n",
       "      <td>1.039761e-09</td>\n",
       "      <td>4.890194e-08</td>\n",
       "      <td>9.958311e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00865.jpg</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>4.269918e-07</td>\n",
       "      <td>3.636755e-08</td>\n",
       "      <td>2.895845e-10</td>\n",
       "      <td>2.451326e-08</td>\n",
       "      <td>5.572800e-07</td>\n",
       "      <td>1.787336e-05</td>\n",
       "      <td>8.063277e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_01548.jpg</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>2.382794e-05</td>\n",
       "      <td>1.964029e-05</td>\n",
       "      <td>1.475374e-06</td>\n",
       "      <td>4.159225e-06</td>\n",
       "      <td>4.894916e-08</td>\n",
       "      <td>2.790045e-06</td>\n",
       "      <td>2.372943e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_06541.jpg</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.185220e-09</td>\n",
       "      <td>1.789494e-10</td>\n",
       "      <td>2.836929e-12</td>\n",
       "      <td>8.936242e-11</td>\n",
       "      <td>4.981517e-10</td>\n",
       "      <td>9.579245e-13</td>\n",
       "      <td>3.438447e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB           BET           DOL           LAG  \\\n",
       "0  img_02082.jpg  0.513207  1.230079e-03  2.379873e-03  2.242678e-04   \n",
       "1  img_02096.jpg  0.999900  9.201301e-11  5.842765e-09  3.926248e-09   \n",
       "2  img_00865.jpg  0.999981  4.269918e-07  3.636755e-08  2.895845e-10   \n",
       "3  img_01548.jpg  0.999948  2.382794e-05  1.964029e-05  1.475374e-06   \n",
       "4  img_06541.jpg  1.000000  7.185220e-09  1.789494e-10  2.836929e-12   \n",
       "\n",
       "            NoF         OTHER         SHARK           YFT  \n",
       "0  1.835492e-01  7.797730e-05  2.959583e-01  3.373205e-03  \n",
       "1  9.943790e-09  1.039761e-09  4.890194e-08  9.958311e-05  \n",
       "2  2.451326e-08  5.572800e-07  1.787336e-05  8.063277e-08  \n",
       "3  4.159225e-06  4.894916e-08  2.790045e-06  2.372943e-09  \n",
       "4  8.936242e-11  4.981517e-10  9.579245e-13  3.438447e-11  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:02.442695Z",
     "start_time": "2020-03-12T22:42:02.439048Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = submission.set_index('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:02.899177Z",
     "start_time": "2020-03-12T22:42:02.896345Z"
    }
   },
   "outputs": [],
   "source": [
    "TEST_DIR_2 = './dataset/the-nature-conservancy-fisheries-monitoring/test_stg2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:03.445080Z",
     "start_time": "2020-03-12T22:42:03.335024Z"
    }
   },
   "outputs": [],
   "source": [
    "test_files_2 = [im for im in os.listdir(TEST_DIR_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:42:03.887074Z",
     "start_time": "2020-03-12T22:42:03.884402Z"
    }
   },
   "outputs": [],
   "source": [
    "test_2 = np.ndarray((len(test_files_2), ROWS, COLS, CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:51:13.168874Z",
     "start_time": "2020-03-12T22:42:04.350189Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, im in enumerate(test_files_2): \n",
    "    test_2[i] = read_image(TEST_DIR_2+im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T22:51:13.862324Z",
     "start_time": "2020-03-12T22:51:13.857440Z"
    }
   },
   "outputs": [],
   "source": [
    "test_2 = test_2.transpose(0,3,1,2)\n",
    "test_2 = torch.from_numpy(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:41:10.994Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds_2 = model(test_2.float())\n",
    "test_preds_2 = test_preds_2.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:41:11.190Z"
    }
   },
   "outputs": [],
   "source": [
    "submission2 = pd.DataFrame(test_preds_2, columns=FISH_CLASSES)\n",
    "\n",
    "submission2.insert(0, 'image', test_files_2)\n",
    "submission2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:41:11.382Z"
    }
   },
   "outputs": [],
   "source": [
    "submission2 = submission2.set_index('image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:41:12.475Z"
    }
   },
   "outputs": [],
   "source": [
    "submission2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:41:13.318Z"
    }
   },
   "outputs": [],
   "source": [
    "final_submission = pd.concat([submission, submission2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-03-12T22:41:13.630Z"
    }
   },
   "outputs": [],
   "source": [
    "final_submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
